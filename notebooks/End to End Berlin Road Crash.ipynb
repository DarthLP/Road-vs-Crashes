{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# End-to-End Berlin Road Crash Analysis Pipeline\n",
        "\n",
        "This notebook reproduces the complete analysis pipeline linking street-level infrastructure quality (Mapillary images) to road safety outcomes (Berlin crash data).\n",
        "\n",
        "## Pipeline Overview\n",
        "\n",
        "1. **Crash and OSM Data Integration**: Aggregate crashes, process OSM road network, match data spatially\n",
        "2. **Baseline Logistic Regression**: Train OSM-only model to predict crash occurrence\n",
        "3. **YOLO Feature Extraction**: Extract visual street quality features using YOLOv8\n",
        "4. **Enhanced Regression**: Train model with YOLO features and compare to baseline\n",
        "5. **CNN Residual Model**: Train CNN to predict residual risk (unexplained by OSM)\n",
        "6. **Grad-CAM Visualization**: Generate interpretability visualizations\n",
        "\n",
        "---\n",
        "\n",
        "## Setup and Imports\n",
        "\n",
        "Setting up the environment, paths, and importing necessary modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().absolute().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Set up paths\n",
        "DATA_RAW = project_root / 'data' / 'raw'\n",
        "DATA_INTERIM = project_root / 'data' / 'interim'\n",
        "DATA_PROCESSED = project_root / 'data' / 'processed'\n",
        "MODELS_DIR = project_root / 'models'\n",
        "REPORTS_DIR = project_root / 'reports'\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Data directories exist:\")\n",
        "print(f\"  - Raw: {DATA_RAW.exists()}\")\n",
        "print(f\"  - Interim: {DATA_INTERIM.exists()}\")\n",
        "print(f\"  - Processed: {DATA_PROCESSED.exists()}\")\n",
        "print(f\"  - Models: {MODELS_DIR.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Crash and OSM Data Integration\n",
        "\n",
        "This section:\n",
        "- Aggregates crash data from multiple years\n",
        "- Processes OSM road network\n",
        "- Matches crashes and images to nearest road segments\n",
        "- Creates 15m cluster dataset with crash matching\n",
        "\n",
        "### 1.1 Aggregate Crash Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if aggregated crashes already exist\n",
        "CRASHES_AGGREGATED = DATA_INTERIM / 'crashes_aggregated.csv'\n",
        "\n",
        "if CRASHES_AGGREGATED.exists():\n",
        "    print(f\"✅ Found existing aggregated crashes: {CRASHES_AGGREGATED}\")\n",
        "    crashes_df = pd.read_csv(CRASHES_AGGREGATED)\n",
        "    print(f\"   Loaded {len(crashes_df):,} crash records\")\n",
        "else:\n",
        "    print(\"⚠️  Aggregated crashes not found. Running aggregation...\")\n",
        "    # Import and run aggregation\n",
        "    from src.features.aggregate_crashes import main as aggregate_crashes\n",
        "    aggregate_crashes()\n",
        "    crashes_df = pd.read_csv(CRASHES_AGGREGATED)\n",
        "    print(f\"✅ Created aggregated crashes: {len(crashes_df):,} records\")\n",
        "\n",
        "print(f\"\\nCrash data summary:\")\n",
        "print(f\"  Columns: {list(crashes_df.columns[:10])}...\")\n",
        "print(f\"  Year range: {crashes_df['UJAHR'].min()}-{crashes_df['UJAHR'].max()}\")\n",
        "print(f\"  Total crashes: {len(crashes_df):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Process OSM Road Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if OSM roads already processed\n",
        "OSM_ROADS = DATA_INTERIM / 'osm_berlin_roads.gpkg'\n",
        "\n",
        "if OSM_ROADS.exists():\n",
        "    print(f\"✅ Found existing OSM roads: {OSM_ROADS}\")\n",
        "    import geopandas as gpd\n",
        "    roads_gdf = gpd.read_file(OSM_ROADS)\n",
        "    print(f\"   Loaded {len(roads_gdf):,} road segments\")\n",
        "else:\n",
        "    print(\"⚠️  OSM roads not found. Running processing...\")\n",
        "    from src.features.process_osm_efficient import main as process_osm\n",
        "    process_osm()\n",
        "    roads_gdf = gpd.read_file(OSM_ROADS)\n",
        "    print(f\"✅ Created OSM roads: {len(roads_gdf):,} segments\")\n",
        "\n",
        "print(f\"\\nOSM roads summary:\")\n",
        "print(f\"  CRS: {roads_gdf.crs}\")\n",
        "print(f\"  Columns: {list(roads_gdf.columns[:10])}...\")\n",
        "if 'road_segment_length_m' in roads_gdf.columns:\n",
        "    print(f\"  Total length: {roads_gdf['road_segment_length_m'].sum() / 1000:.1f} km\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Match Crashes and Images to OSM Roads\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if OSM-matched data already exists\n",
        "CRASHES_WITH_OSM = DATA_PROCESSED / 'crashes_with_osm.csv'\n",
        "MAPILLARY_WITH_OSM = DATA_PROCESSED / 'mapillary_with_osm.csv'\n",
        "\n",
        "if CRASHES_WITH_OSM.exists() and MAPILLARY_WITH_OSM.exists():\n",
        "    print(f\"✅ Found existing OSM-matched data\")\n",
        "    crashes_osm = pd.read_csv(CRASHES_WITH_OSM)\n",
        "    images_osm = pd.read_csv(MAPILLARY_WITH_OSM)\n",
        "    print(f\"   Crashes with OSM: {len(crashes_osm):,} ({crashes_osm['dist_to_road_m'].notna().sum():,} matched)\")\n",
        "    print(f\"   Images with OSM: {len(images_osm):,} ({images_osm['dist_to_road_m'].notna().sum():,} matched)\")\n",
        "else:\n",
        "    print(\"⚠️  OSM-matched data not found. Running spatial matching...\")\n",
        "    from src.features.snap_to_roads import main as snap_to_roads\n",
        "    snap_to_roads()\n",
        "    crashes_osm = pd.read_csv(CRASHES_WITH_OSM)\n",
        "    images_osm = pd.read_csv(MAPILLARY_WITH_OSM)\n",
        "    print(f\"✅ Created OSM-matched data\")\n",
        "\n",
        "# Calculate match rates\n",
        "if 'dist_to_road_m' in crashes_osm.columns:\n",
        "    crash_match_rate = crashes_osm['dist_to_road_m'].notna().sum() / len(crashes_osm) * 100\n",
        "    print(f\"\\nCrash match rate: {crash_match_rate:.1f}%\")\n",
        "\n",
        "if 'dist_to_road_m' in images_osm.columns:\n",
        "    image_match_rate = images_osm['dist_to_road_m'].notna().sum() / len(images_osm) * 100\n",
        "    print(f\"Image match rate: {image_match_rate:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Create 15m Cluster Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if cluster dataset already exists\n",
        "CLUSTERS_DATA = DATA_PROCESSED / 'clusters_with_crashes.csv'\n",
        "\n",
        "if CLUSTERS_DATA.exists():\n",
        "    print(f\"✅ Found existing cluster dataset: {CLUSTERS_DATA}\")\n",
        "    clusters_df = pd.read_csv(CLUSTERS_DATA)\n",
        "    print(f\"   Loaded {len(clusters_df):,} clusters\")\n",
        "    print(f\"   Clusters with crashes: {(clusters_df['match_label'] == 1).sum():,}\")\n",
        "else:\n",
        "    print(\"⚠️  Cluster dataset not found. Creating clusters...\")\n",
        "    from src.features.create_cluster_dataset import main as create_clusters\n",
        "    create_clusters()\n",
        "    clusters_df = pd.read_csv(CLUSTERS_DATA)\n",
        "    print(f\"✅ Created cluster dataset: {len(clusters_df):,} clusters\")\n",
        "\n",
        "print(f\"\\nCluster dataset summary:\")\n",
        "print(f\"  Total clusters: {len(clusters_df):,}\")\n",
        "print(f\"  Clusters with crashes: {(clusters_df['match_label'] == 1).sum():,} ({100 * (clusters_df['match_label'] == 1).mean():.1f}%)\")\n",
        "if 'split' in clusters_df.columns:\n",
        "    print(f\"\\nSplit distribution:\")\n",
        "    print(clusters_df['split'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Baseline Logistic Regression (OSM-only)\n",
        "\n",
        "This section:\n",
        "- Trains a baseline logistic regression using only structured OSM road attributes\n",
        "- Predicts crash occurrence (binary classification)\n",
        "- Computes residuals (actual - predicted probability) for CNN target\n",
        "- Evaluates model performance on train/val/test splits\n",
        "\n",
        "### 2.1 Load Cluster Data with Splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if residuals already computed\n",
        "CLUSTERS_TRAIN_RES = DATA_PROCESSED / 'clusters_train_with_residuals.csv'\n",
        "CLUSTERS_VAL_RES = DATA_PROCESSED / 'clusters_val_with_residuals.csv'\n",
        "CLUSTERS_TEST_RES = DATA_PROCESSED / 'clusters_test_with_residuals.csv'\n",
        "BASELINE_MODEL = MODELS_DIR / 'baseline_logistic_regression.pkl'\n",
        "\n",
        "if all([CLUSTERS_TRAIN_RES.exists(), CLUSTERS_VAL_RES.exists(), CLUSTERS_TEST_RES.exists(), BASELINE_MODEL.exists()]):\n",
        "    print(f\"✅ Found existing baseline model and residuals\")\n",
        "    clusters_train = pd.read_csv(CLUSTERS_TRAIN_RES)\n",
        "    clusters_val = pd.read_csv(CLUSTERS_VAL_RES)\n",
        "    clusters_test = pd.read_csv(CLUSTERS_TEST_RES)\n",
        "    print(f\"   Train: {len(clusters_train):,} clusters\")\n",
        "    print(f\"   Val: {len(clusters_val):,} clusters\")\n",
        "    print(f\"   Test: {len(clusters_test):,} clusters\")\n",
        "    \n",
        "    # Load model metadata\n",
        "    import joblib\n",
        "    baseline_model = joblib.load(BASELINE_MODEL)\n",
        "    with open(MODELS_DIR / 'baseline_logistic_regression_metadata.json', 'r') as f:\n",
        "        baseline_metadata = json.load(f)\n",
        "    print(f\"   Model trained with {baseline_metadata.get('n_features', 'N/A')} features\")\n",
        "else:\n",
        "    print(\"⚠️  Baseline model not found. Training baseline logistic regression...\")\n",
        "    from src.modeling.baseline_logistic_regression import main as train_baseline\n",
        "    train_baseline()\n",
        "    \n",
        "    clusters_train = pd.read_csv(CLUSTERS_TRAIN_RES)\n",
        "    clusters_val = pd.read_csv(CLUSTERS_VAL_RES)\n",
        "    clusters_test = pd.read_csv(CLUSTERS_TEST_RES)\n",
        "    baseline_model = joblib.load(BASELINE_MODEL)\n",
        "    print(f\"✅ Trained baseline model\")\n",
        "\n",
        "# Display residual statistics\n",
        "if 'residual' in clusters_train.columns:\n",
        "    print(f\"\\nResidual statistics:\")\n",
        "    print(f\"  Train - Mean: {clusters_train['residual'].mean():.4f}, Std: {clusters_train['residual'].std():.4f}\")\n",
        "    print(f\"  Val - Mean: {clusters_val['residual'].mean():.4f}, Std: {clusters_val['residual'].std():.4f}\")\n",
        "    print(f\"  Test - Mean: {clusters_test['residual'].mean():.4f}, Std: {clusters_test['residual'].std():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Display Baseline Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load baseline metrics\n",
        "BASELINE_METRICS = REPORTS_DIR / 'Regression_beforeCNN' / 'baseline_metrics_comparison.csv'\n",
        "\n",
        "if BASELINE_METRICS.exists():\n",
        "    baseline_metrics = pd.read_csv(BASELINE_METRICS)\n",
        "    print(\"Baseline Logistic Regression Performance:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(baseline_metrics.to_string(index=False))\n",
        "    \n",
        "    # Create visualization\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Metrics comparison\n",
        "    metric_cols = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC_AUC']\n",
        "    metrics_data = baseline_metrics.set_index('Split')[metric_cols]\n",
        "    \n",
        "    metrics_data.plot(kind='bar', ax=axes[0], rot=0)\n",
        "    axes[0].set_title('Baseline Model Metrics by Split')\n",
        "    axes[0].set_ylabel('Score')\n",
        "    axes[0].legend(loc='best')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Residual distribution\n",
        "    if 'residual' in clusters_test.columns:\n",
        "        axes[1].hist(clusters_test['residual'], bins=50, alpha=0.7, edgecolor='black')\n",
        "        axes[1].axvline(0, color='red', linestyle='--', label='Zero residual')\n",
        "        axes[1].set_xlabel('Residual (Actual - Predicted)')\n",
        "        axes[1].set_ylabel('Frequency')\n",
        "        axes[1].set_title('Test Set Residual Distribution')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠️  Baseline metrics not found. Run baseline_logistic_regression.py to generate.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: YOLO Inference and Feature Extraction\n",
        "\n",
        "This section:\n",
        "- Loads trained YOLOv8 model\n",
        "- Extracts visual street quality features using ROI filtering\n",
        "- Computes per-cluster aggregated metrics\n",
        "- Winsorizes features to reduce outlier impact\n",
        "\n",
        "### 3.1 Load YOLO Model and Extract Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if YOLO features already extracted\n",
        "CLUSTERS_TRAIN_YOLO = DATA_PROCESSED / 'clusters_train_with_yolo_roi.csv'\n",
        "CLUSTERS_VAL_YOLO = DATA_PROCESSED / 'clusters_val_with_yolo_roi.csv'\n",
        "CLUSTERS_TEST_YOLO = DATA_PROCESSED / 'clusters_test_with_yolo_roi.csv'\n",
        "YOLO_MODEL_PATH = project_root / 'runs' / 'detect' / 'train' / 'weights' / 'best.pt'\n",
        "\n",
        "if all([CLUSTERS_TRAIN_YOLO.exists(), CLUSTERS_VAL_YOLO.exists(), CLUSTERS_TEST_YOLO.exists()]):\n",
        "    print(f\"✅ Found existing YOLO features\")\n",
        "    clusters_train_yolo = pd.read_csv(CLUSTERS_TRAIN_YOLO)\n",
        "    clusters_val_yolo = pd.read_csv(CLUSTERS_VAL_YOLO)\n",
        "    clusters_test_yolo = pd.read_csv(CLUSTERS_TEST_YOLO)\n",
        "    print(f\"   Train: {len(clusters_train_yolo):,} clusters\")\n",
        "    print(f\"   Val: {len(clusters_val_yolo):,} clusters\")\n",
        "    print(f\"   Test: {len(clusters_test_yolo):,} clusters\")\n",
        "    \n",
        "    # Display YOLO feature statistics\n",
        "    if 'street_quality_roi_winz' in clusters_train_yolo.columns:\n",
        "        print(f\"\\nYOLO Feature (street_quality_roi_winz) statistics:\")\n",
        "        print(f\"  Train - Mean: {clusters_train_yolo['street_quality_roi_winz'].mean():.4f}, \"\n",
        "              f\"Std: {clusters_train_yolo['street_quality_roi_winz'].std():.4f}\")\n",
        "        print(f\"  Val - Mean: {clusters_val_yolo['street_quality_roi_winz'].mean():.4f}, \"\n",
        "              f\"Std: {clusters_val_yolo['street_quality_roi_winz'].std():.4f}\")\n",
        "        print(f\"  Test - Mean: {clusters_test_yolo['street_quality_roi_winz'].mean():.4f}, \"\n",
        "              f\"Std: {clusters_test_yolo['street_quality_roi_winz'].std():.4f}\")\n",
        "else:\n",
        "    if not YOLO_MODEL_PATH.exists():\n",
        "        print(f\"⚠️  YOLO model not found at {YOLO_MODEL_PATH}\")\n",
        "        print(\"   Please train YOLO model first using train_yolo_cz_no.py\")\n",
        "    else:\n",
        "        print(\"⚠️  YOLO features not found. Extracting features...\")\n",
        "        print(\"   (This may take a while - running YOLO inference on images)\")\n",
        "        from src.modeling.extract_yolo_features import main as extract_yolo\n",
        "        extract_yolo()\n",
        "        \n",
        "        clusters_train_yolo = pd.read_csv(CLUSTERS_TRAIN_YOLO)\n",
        "        clusters_val_yolo = pd.read_csv(CLUSTERS_VAL_YOLO)\n",
        "        clusters_test_yolo = pd.read_csv(CLUSTERS_TEST_YOLO)\n",
        "        print(f\"✅ Extracted YOLO features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Visualize YOLO Feature Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if all([CLUSTERS_TRAIN_YOLO.exists(), CLUSTERS_VAL_YOLO.exists(), CLUSTERS_TEST_YOLO.exists()]):\n",
        "    clusters_train_yolo = pd.read_csv(CLUSTERS_TRAIN_YOLO)\n",
        "    clusters_val_yolo = pd.read_csv(CLUSTERS_VAL_YOLO)\n",
        "    clusters_test_yolo = pd.read_csv(CLUSTERS_TEST_YOLO)\n",
        "    \n",
        "    if 'street_quality_roi_winz' in clusters_train_yolo.columns:\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "        sns.set_style(\"whitegrid\")\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Distribution by split\n",
        "        splits_data = pd.concat([\n",
        "            clusters_train_yolo[['street_quality_roi_winz']].assign(Split='Train'),\n",
        "            clusters_val_yolo[['street_quality_roi_winz']].assign(Split='Val'),\n",
        "            clusters_test_yolo[['street_quality_roi_winz']].assign(Split='Test')\n",
        "        ])\n",
        "        \n",
        "        splits_data.boxplot(column='street_quality_roi_winz', by='Split', ax=axes[0])\n",
        "        axes[0].set_title('YOLO Feature Distribution by Split')\n",
        "        axes[0].set_ylabel('Street Quality ROI (Winsorized)')\n",
        "        axes[0].set_xlabel('')\n",
        "        plt.suptitle('')\n",
        "        \n",
        "        # Correlation with crash label\n",
        "        all_yolo = pd.concat([\n",
        "            clusters_train_yolo[['street_quality_roi_winz', 'match_label']].assign(Split='Train'),\n",
        "            clusters_val_yolo[['street_quality_roi_winz', 'match_label']].assign(Split='Val'),\n",
        "            clusters_test_yolo[['street_quality_roi_winz', 'match_label']].assign(Split='Test')\n",
        "        ])\n",
        "        \n",
        "        for split in ['Train', 'Val', 'Test']:\n",
        "            split_data = all_yolo[all_yolo['Split'] == split]\n",
        "            axes[1].scatter(\n",
        "                split_data['street_quality_roi_winz'], \n",
        "                split_data['match_label'],\n",
        "                alpha=0.3, \n",
        "                label=split,\n",
        "                s=20\n",
        "            )\n",
        "        \n",
        "        axes[1].set_xlabel('Street Quality ROI (Winsorized)')\n",
        "        axes[1].set_ylabel('Crash Occurrence (0/1)')\n",
        "        axes[1].set_title('YOLO Feature vs Crash Label')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Correlation coefficient\n",
        "        for split, df in [('Train', clusters_train_yolo), ('Val', clusters_val_yolo), ('Test', clusters_test_yolo)]:\n",
        "            if 'street_quality_roi_winz' in df.columns and 'match_label' in df.columns:\n",
        "                corr = df['street_quality_roi_winz'].corr(df['match_label'])\n",
        "                print(f\"{split} correlation (YOLO feature vs crash): {corr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Enhanced Regression with YOLO Features\n",
        "\n",
        "This section:\n",
        "- Trains enhanced logistic regression with baseline features + YOLO features\n",
        "- Compares performance against baseline model\n",
        "- Generates comparison visualizations and metrics\n",
        "\n",
        "### 4.1 Train Enhanced Model with YOLO Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if enhanced model already trained\n",
        "YOLO_MODEL = MODELS_DIR / 'logistic_regression_with_yolo.pkl'\n",
        "YOLO_METRICS = REPORTS_DIR / 'Regression_withYOLO' / 'logistic_regression_with_yolo_metrics.csv'\n",
        "\n",
        "if YOLO_MODEL.exists() and YOLO_METRICS.exists():\n",
        "    print(f\"✅ Found existing enhanced YOLO model\")\n",
        "    import joblib\n",
        "    yolo_model = joblib.load(YOLO_MODEL)\n",
        "    yolo_metrics = pd.read_csv(YOLO_METRICS)\n",
        "    \n",
        "    print(\"\\nEnhanced Model (with YOLO) Performance:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(yolo_metrics.to_string(index=False))\n",
        "else:\n",
        "    if not all([CLUSTERS_TRAIN_YOLO.exists(), CLUSTERS_VAL_YOLO.exists(), CLUSTERS_TEST_YOLO.exists()]):\n",
        "        print(\"⚠️  YOLO features not found. Run Section 3 first.\")\n",
        "    else:\n",
        "        print(\"⚠️  Enhanced model not found. Training enhanced logistic regression...\")\n",
        "        from src.modeling.logistic_regression_with_yolo import main as train_yolo_model\n",
        "        train_yolo_model()\n",
        "        \n",
        "        yolo_model = joblib.load(YOLO_MODEL)\n",
        "        yolo_metrics = pd.read_csv(YOLO_METRICS)\n",
        "        print(f\"✅ Trained enhanced model\")\n",
        "\n",
        "# Load metadata\n",
        "if (MODELS_DIR / 'logistic_regression_with_yolo_metadata.json').exists():\n",
        "    with open(MODELS_DIR / 'logistic_regression_with_yolo_metadata.json', 'r') as f:\n",
        "        yolo_metadata = json.load(f)\n",
        "    print(f\"\\nModel info:\")\n",
        "    print(f\"  Features: {yolo_metadata.get('n_features', 'N/A')}\")\n",
        "    print(f\"  Includes YOLO feature: street_quality_roi_winz\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Compare Baseline vs Enhanced Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if comparison already done\n",
        "COMPARISON_METRICS = REPORTS_DIR / 'Comparison_Baseline_vs_YOLO' / 'metrics_comparison.csv'\n",
        "\n",
        "if COMPARISON_METRICS.exists():\n",
        "    comparison_df = pd.read_csv(COMPARISON_METRICS)\n",
        "    print(\"Model Comparison: Baseline vs Enhanced (with YOLO)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(comparison_df.to_string(index=False))\n",
        "    \n",
        "    # Create comparison visualization\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Metrics comparison bar chart\n",
        "    if 'Split' in comparison_df.columns and 'Model' in comparison_df.columns:\n",
        "        metric_cols = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC_AUC']\n",
        "        available_metrics = [col for col in metric_cols if col in comparison_df.columns]\n",
        "        \n",
        "        if available_metrics:\n",
        "            comparison_pivot = comparison_df.pivot_table(\n",
        "                index='Split', \n",
        "                columns='Model', \n",
        "                values=available_metrics[0]\n",
        "            )\n",
        "            comparison_pivot.plot(kind='bar', ax=axes[0], rot=0)\n",
        "            axes[0].set_title('Model Comparison by Split')\n",
        "            axes[0].set_ylabel('Score')\n",
        "            axes[0].legend(title='Model', loc='best')\n",
        "            axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Delta metrics if available\n",
        "    DELTA_METRICS = REPORTS_DIR / 'Comparison_Baseline_vs_YOLO' / 'test_metrics_delta.csv'\n",
        "    if DELTA_METRICS.exists():\n",
        "        delta_df = pd.read_csv(DELTA_METRICS)\n",
        "        if len(delta_df) > 0:\n",
        "            delta_cols = [col for col in delta_df.columns if col.startswith('Δ')]\n",
        "            if delta_cols:\n",
        "                delta_df[delta_cols[0]].plot(kind='barh', ax=axes[1])\n",
        "                axes[1].axvline(0, color='red', linestyle='--', alpha=0.5)\n",
        "                axes[1].set_title(f'Performance Delta (Enhanced - Baseline)')\n",
        "                axes[1].set_xlabel('Δ Score')\n",
        "                axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠️  Comparison metrics not found. Running comparison...\")\n",
        "    from src.modeling.compare_baseline_vs_yolo import main as compare_models\n",
        "    compare_models()\n",
        "    comparison_df = pd.read_csv(COMPARISON_METRICS)\n",
        "    print(\"✅ Generated comparison metrics\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: CNN Residual Model\n",
        "\n",
        "This section:\n",
        "- Prepares CNN dataset (one image per cluster with residual label)\n",
        "- Trains ResNet18 regression model to predict residual risk\n",
        "- Evaluates model and ranks high-risk images\n",
        "\n",
        "### 5.1 Prepare CNN Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if CNN dataset already prepared\n",
        "CNN_DATASET = DATA_PROCESSED / 'cnn_samples_residual.csv'\n",
        "\n",
        "if CNN_DATASET.exists():\n",
        "    print(f\"✅ Found existing CNN dataset: {CNN_DATASET}\")\n",
        "    cnn_samples = pd.read_csv(CNN_DATASET)\n",
        "    print(f\"   Loaded {len(cnn_samples):,} samples\")\n",
        "    print(f\"   Train: {(cnn_samples['split'] == 'train').sum():,}\")\n",
        "    print(f\"   Val: {(cnn_samples['split'] == 'val').sum():,}\")\n",
        "    print(f\"   Test: {(cnn_samples['split'] == 'test').sum():,}\")\n",
        "    \n",
        "    print(f\"\\nResidual statistics by split:\")\n",
        "    print(cnn_samples.groupby('split')['residual'].agg(['count', 'mean', 'std', 'min', 'max']).round(4))\n",
        "else:\n",
        "    if not all([CLUSTERS_TRAIN_RES.exists(), CLUSTERS_VAL_RES.exists(), CLUSTERS_TEST_RES.exists()]):\n",
        "        print(\"⚠️  Residual data not found. Run Section 2 first to generate residuals.\")\n",
        "    else:\n",
        "        print(\"⚠️  CNN dataset not found. Preparing dataset...\")\n",
        "        from src.modeling.prepare_cnn_dataset import main as prepare_cnn\n",
        "        prepare_cnn()\n",
        "        cnn_samples = pd.read_csv(CNN_DATASET)\n",
        "        print(f\"✅ Created CNN dataset: {len(cnn_samples):,} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Train CNN Residual Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if CNN model already trained\n",
        "CNN_MODEL = MODELS_DIR / 'cnn_residual_best.pth'\n",
        "CNN_PREDICTIONS = DATA_PROCESSED / 'cnn_test_predictions.csv'\n",
        "\n",
        "if CNN_MODEL.exists():\n",
        "    print(f\"✅ Found existing CNN model: {CNN_MODEL}\")\n",
        "    \n",
        "    # Check for training log\n",
        "    TRAINING_LOG = REPORTS_DIR / 'CNN' / 'training_log.csv'\n",
        "    if TRAINING_LOG.exists():\n",
        "        training_log = pd.read_csv(TRAINING_LOG)\n",
        "        print(f\"   Training epochs: {len(training_log)}\")\n",
        "        print(f\"   Best validation MSE: {training_log['val_mse'].min():.6f}\")\n",
        "        print(f\"\\nLast 5 epochs:\")\n",
        "        print(training_log.tail().to_string(index=False))\n",
        "    \n",
        "    # Check for test predictions\n",
        "    if CNN_PREDICTIONS.exists():\n",
        "        cnn_preds = pd.read_csv(CNN_PREDICTIONS)\n",
        "        print(f\"\\nTest predictions:\")\n",
        "        print(f\"   Samples: {len(cnn_preds):,}\")\n",
        "        print(f\"   Mean predicted residual: {cnn_preds['predicted_residual'].mean():.4f}\")\n",
        "        print(f\"   Std predicted residual: {cnn_preds['predicted_residual'].std():.4f}\")\n",
        "        \n",
        "        # Correlation with true residuals\n",
        "        if 'true_residual' in cnn_preds.columns:\n",
        "            corr = cnn_preds['predicted_residual'].corr(cnn_preds['true_residual'])\n",
        "            print(f\"   Correlation (predicted vs true): {corr:.4f}\")\n",
        "else:\n",
        "    if not CNN_DATASET.exists():\n",
        "        print(\"⚠️  CNN dataset not found. Run Section 5.1 first.\")\n",
        "    else:\n",
        "        print(\"⚠️  CNN model not found.\")\n",
        "        print(\"   Training CNN can take a long time (20-30 minutes).\")\n",
        "        print(\"   To train, run: python src/modeling/train_cnn_residual.py\")\n",
        "        print(\"   Or uncomment the code below to train in this notebook:\")\n",
        "        \n",
        "        # Option to train (commented out by default)\n",
        "        # from src.modeling.train_cnn_residual import main as train_cnn\n",
        "        # train_cnn()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Visualize CNN Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if CNN_PREDICTIONS.exists() and CNN_MODEL.exists():\n",
        "    cnn_preds = pd.read_csv(CNN_PREDICTIONS)\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Scatter plot: predicted vs true residuals\n",
        "    if 'true_residual' in cnn_preds.columns:\n",
        "        axes[0].scatter(cnn_preds['true_residual'], cnn_preds['predicted_residual'], \n",
        "                       alpha=0.5, s=20)\n",
        "        axes[0].plot([cnn_preds['true_residual'].min(), cnn_preds['true_residual'].max()],\n",
        "                    [cnn_preds['true_residual'].min(), cnn_preds['true_residual'].max()],\n",
        "                    'r--', label='Perfect prediction')\n",
        "        axes[0].set_xlabel('True Residual')\n",
        "        axes[0].set_ylabel('Predicted Residual')\n",
        "        axes[0].set_title('CNN Residual Prediction')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "        corr = cnn_preds['predicted_residual'].corr(cnn_preds['true_residual'])\n",
        "        axes[0].text(0.05, 0.95, f'Correlation: {corr:.4f}', \n",
        "                    transform=axes[0].transAxes, verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    # Distribution of predicted residuals\n",
        "    axes[1].hist(cnn_preds['predicted_residual'], bins=50, alpha=0.7, edgecolor='black')\n",
        "    axes[1].axvline(cnn_preds['predicted_residual'].mean(), color='red', \n",
        "                   linestyle='--', label=f\"Mean: {cnn_preds['predicted_residual'].mean():.4f}\")\n",
        "    axes[1].set_xlabel('Predicted Residual')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].set_title('Predicted Residual Distribution')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Check for high-risk images ranking\n",
        "    HIGH_RISK = DATA_PROCESSED / 'cnn_test_top_visual_risks.csv'\n",
        "    if HIGH_RISK.exists():\n",
        "        high_risk = pd.read_csv(HIGH_RISK)\n",
        "        print(f\"\\nTop 10 highest predicted residual (high-risk) images:\")\n",
        "        print(high_risk.head(10)[['cluster_id', 'predicted_residual', 'true_residual']].to_string(index=False))\n",
        "else:\n",
        "    print(\"⚠️  CNN predictions not found. Train CNN model first (Section 5.2).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if Grad-CAM already generated\n",
        "GRADCAM_DIR = REPORTS_DIR / 'CNN' / 'gradcam'\n",
        "GRADCAM_REPORT = GRADCAM_DIR / 'gradcam_analysis_report.md'\n",
        "\n",
        "if GRADCAM_DIR.exists() and GRADCAM_REPORT.exists():\n",
        "    print(f\"✅ Found existing Grad-CAM visualizations: {GRADCAM_DIR}\")\n",
        "    \n",
        "    # Count generated files\n",
        "    heatmap_count = len(list(GRADCAM_DIR.glob('*_heatmap.jpg')))\n",
        "    overlay_count = len(list(GRADCAM_DIR.glob('*_overlay.jpg')))\n",
        "    grid_count = len(list(GRADCAM_DIR.glob('*_grid.png')))\n",
        "    \n",
        "    print(f\"   Heatmaps: {heatmap_count}\")\n",
        "    print(f\"   Overlays: {overlay_count}\")\n",
        "    print(f\"   Grids: {grid_count}\")\n",
        "    \n",
        "    # Display report summary\n",
        "    if GRADCAM_REPORT.exists():\n",
        "        with open(GRADCAM_REPORT, 'r') as f:\n",
        "            report_content = f.read()\n",
        "            # Extract key statistics\n",
        "            print(f\"\\nGrad-CAM Analysis Report:\")\n",
        "            print(\"=\" * 60)\n",
        "            lines = report_content.split('\\n')[:20]  # First 20 lines\n",
        "            for line in lines:\n",
        "                if line.strip():\n",
        "                    print(line)\n",
        "            print(\"\\n... (see full report for complete analysis)\")\n",
        "else:\n",
        "    if not CNN_MODEL.exists():\n",
        "        print(\"⚠️  CNN model not found. Train CNN model first (Section 5.2).\")\n",
        "    elif not CNN_DATASET.exists():\n",
        "        print(\"⚠️  CNN dataset not found. Run Section 5.1 first.\")\n",
        "    else:\n",
        "        print(\"⚠️  Grad-CAM visualizations not found.\")\n",
        "        print(\"   Generating Grad-CAM can take a while (5-10 minutes).\")\n",
        "        print(\"   To generate, run:\")\n",
        "        print(\"   python src/modeling/visualize_gradcam.py --checkpoint models/cnn_residual_best.pth --num_samples 20\")\n",
        "        print(\"   Or uncomment the code below to generate in this notebook:\")\n",
        "        \n",
        "        # Option to generate (commented out by default)\n",
        "        # import argparse\n",
        "        # from src.modeling.visualize_gradcam import main as visualize_gradcam\n",
        "        # # Create mock args\n",
        "        # args = argparse.Namespace(\n",
        "        #     checkpoint=str(CNN_MODEL),\n",
        "        #     num_samples=20,\n",
        "        #     method='gradcam',\n",
        "        #     colormap='jet',\n",
        "        #     save_stats=True,\n",
        "        #     output_dir=str(GRADCAM_DIR)\n",
        "        # )\n",
        "        # visualize_gradcam()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Display Sample Grad-CAM Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if GRADCAM_DIR.exists():\n",
        "    from IPython.display import Image, display, Markdown\n",
        "    import glob\n",
        "    \n",
        "    # Find sample grids\n",
        "    grid_files = sorted(glob.glob(str(GRADCAM_DIR / '*_grid.png')))\n",
        "    \n",
        "    if grid_files:\n",
        "        print(\"Sample Grad-CAM Grid Visualizations:\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        # Display first few grids\n",
        "        for i, grid_file in enumerate(grid_files[:2]):\n",
        "            print(f\"\\nGrid {i+1}:\")\n",
        "            display(Image(filename=grid_file, width=800))\n",
        "    else:\n",
        "        print(\"⚠️  Grid visualizations not found. Generate Grad-CAM first.\")\n",
        "    \n",
        "    # Display report if available\n",
        "    if GRADCAM_REPORT.exists():\n",
        "        with open(GRADCAM_REPORT, 'r') as f:\n",
        "            report_md = f.read()\n",
        "        display(Markdown(report_md))\n",
        "else:\n",
        "    print(\"⚠️  Grad-CAM visualizations not found. Generate them first (Section 6.1).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Key Findings and Model Comparison\n",
        "\n",
        "This section summarizes the key findings across all pipeline steps and compares model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"END-TO-END PIPELINE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Data Integration Summary\n",
        "print(\"\\n1. DATA INTEGRATION:\")\n",
        "print(\"   \" + \"-\" * 76)\n",
        "if CLUSTERS_DATA.exists():\n",
        "    clusters_summary = clusters_df if 'clusters_df' in locals() else pd.read_csv(CLUSTERS_DATA)\n",
        "    print(f\"   Total clusters: {len(clusters_summary):,}\")\n",
        "    print(f\"   Clusters with crashes: {(clusters_summary['match_label'] == 1).sum():,} \"\n",
        "          f\"({100 * (clusters_summary['match_label'] == 1).mean():.1f}%)\")\n",
        "\n",
        "# 2. Baseline Model Summary\n",
        "print(\"\\n2. BASELINE MODEL (OSM-only):\")\n",
        "print(\"   \" + \"-\" * 76)\n",
        "BASELINE_METRICS = REPORTS_DIR / 'Regression_beforeCNN' / 'baseline_metrics_comparison.csv'\n",
        "if BASELINE_METRICS.exists():\n",
        "    baseline_metrics = pd.read_csv(BASELINE_METRICS)\n",
        "    test_metrics = baseline_metrics[baseline_metrics['Split'] == 'Test']\n",
        "    if len(test_metrics) > 0:\n",
        "        row = test_metrics.iloc[0]\n",
        "        if 'ROC_AUC' in row:\n",
        "            print(f\"   Test ROC AUC: {row['ROC_AUC']:.4f}\")\n",
        "        if 'F1' in row:\n",
        "            print(f\"   Test F1: {row['F1']:.4f}\")\n",
        "        if 'Precision' in row:\n",
        "            print(f\"   Test Precision: {row['Precision']:.4f}\")\n",
        "        if 'Recall' in row:\n",
        "            print(f\"   Test Recall: {row['Recall']:.4f}\")\n",
        "\n",
        "# 3. Enhanced Model Summary\n",
        "print(\"\\n3. ENHANCED MODEL (OSM + YOLO):\")\n",
        "print(\"   \" + \"-\" * 76)\n",
        "YOLO_METRICS = REPORTS_DIR / 'Regression_withYOLO' / 'logistic_regression_with_yolo_metrics.csv'\n",
        "if YOLO_METRICS.exists():\n",
        "    yolo_metrics = pd.read_csv(YOLO_METRICS)\n",
        "    test_yolo = yolo_metrics[yolo_metrics['Split'] == 'Test']\n",
        "    if len(test_yolo) > 0:\n",
        "        row = test_yolo.iloc[0]\n",
        "        if 'ROC_AUC' in row:\n",
        "            print(f\"   Test ROC AUC: {row['ROC_AUC']:.4f}\")\n",
        "        if 'F1' in row:\n",
        "            print(f\"   Test F1: {row['F1']:.4f}\")\n",
        "        if 'Precision' in row:\n",
        "            print(f\"   Test Precision: {row['Precision']:.4f}\")\n",
        "        if 'Recall' in row:\n",
        "            print(f\"   Test Recall: {row['Recall']:.4f}\")\n",
        "\n",
        "# 4. Model Comparison\n",
        "print(\"\\n4. MODEL COMPARISON:\")\n",
        "print(\"   \" + \"-\" * 76)\n",
        "COMPARISON_METRICS = REPORTS_DIR / 'Comparison_Baseline_vs_YOLO' / 'metrics_comparison.csv'\n",
        "if COMPARISON_METRICS.exists():\n",
        "    comp_metrics = pd.read_csv(COMPARISON_METRICS)\n",
        "    test_baseline = comp_metrics[(comp_metrics['Split'] == 'Test') & \n",
        "                                  (comp_metrics['Model'] == 'Baseline')]\n",
        "    test_yolo = comp_metrics[(comp_metrics['Split'] == 'Test') & \n",
        "                             (comp_metrics['Model'] == 'Enhanced')]\n",
        "    \n",
        "    if len(test_baseline) > 0 and len(test_yolo) > 0:\n",
        "        bl_row = test_baseline.iloc[0]\n",
        "        yolo_row = test_yolo.iloc[0]\n",
        "        \n",
        "        if 'ROC_AUC' in bl_row and 'ROC_AUC' in yolo_row:\n",
        "            delta_auc = yolo_row['ROC_AUC'] - bl_row['ROC_AUC']\n",
        "            print(f\"   Δ ROC AUC (Enhanced - Baseline): {delta_auc:+.4f}\")\n",
        "        \n",
        "        if 'F1' in bl_row and 'F1' in yolo_row:\n",
        "            delta_f1 = yolo_row['F1'] - bl_row['F1']\n",
        "            print(f\"   Δ F1 (Enhanced - Baseline): {delta_f1:+.4f}\")\n",
        "\n",
        "# 5. CNN Model Summary\n",
        "print(\"\\n5. CNN RESIDUAL MODEL:\")\n",
        "print(\"   \" + \"-\" * 76)\n",
        "CNN_PREDICTIONS = DATA_PROCESSED / 'cnn_test_predictions.csv'\n",
        "if CNN_PREDICTIONS.exists():\n",
        "    cnn_preds = pd.read_csv(CNN_PREDICTIONS)\n",
        "    if 'true_residual' in cnn_preds.columns:\n",
        "        corr = cnn_preds['predicted_residual'].corr(cnn_preds['true_residual'])\n",
        "        print(f\"   Test correlation (predicted vs true residual): {corr:.4f}\")\n",
        "        print(f\"   Test samples: {len(cnn_preds):,}\")\n",
        "\n",
        "# 6. Grad-CAM Summary\n",
        "print(\"\\n6. GRAD-CAM VISUALIZATION:\")\n",
        "print(\"   \" + \"-\" * 76)\n",
        "GRADCAM_DIR = REPORTS_DIR / 'CNN' / 'gradcam'\n",
        "if GRADCAM_DIR.exists():\n",
        "    print(f\"   Visualizations generated: {GRADCAM_DIR}\")\n",
        "    print(f\"   Analysis report available: {(GRADCAM_DIR / 'gradcam_analysis_report.md').exists()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Pipeline complete! All results saved to data/processed/, models/, and reports/\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
